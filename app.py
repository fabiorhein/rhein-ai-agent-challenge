import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px  # Necess√°rio para o exec
import matplotlib.pyplot as plt
import numpy as np
from uuid import uuid4
import time

# Importa√ß√µes dos m√≥dulos do projeto
from utils.config import get_config
from utils.memory import SupabaseMemory
from utils.data_loader import load_csv, get_dataset_info
from utils.chart_cache import exec_with_cache  # Import do cache de gr√°ficos
from components.ui_components import build_sidebar, display_chat_message, display_code_with_streamlit_suggestion
from components.notebook_generator import create_jupyter_notebook
from components.suggestion_generator import generate_dynamic_suggestions, get_fallback_suggestions, extract_conversation_context

# Importa√ß√£o dos agentes
from agents.coordinator import run_coordinator
from agents.data_analyst import run_data_analyst
from agents.visualization import run_visualization
from agents.consultant import run_consultant
from agents.code_generator import run_code_generator
from agents.agent_setup import get_dataset_preview

# --- Configura√ß√£o da P√°gina e Estado da Sess√£o ---
st.set_page_config(layout="wide", page_title="InsightAgent EDA")

# Configura√ß√£o de debug (pode ser alterada para False em produ√ß√£o)
DEBUG_MODE = False

# Inicializa o estado da sess√£o
if 'session_id' not in st.session_state:
    st.session_state.session_id = None
if 'user_id' not in st.session_state:
    st.session_state.user_id = str(uuid4())
if 'df' not in st.session_state:
    st.session_state.df = None
if 'df_info' not in st.session_state:
    st.session_state.df_info = None
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = ""
if 'all_analyses_history' not in st.session_state:
    st.session_state.all_analyses_history = ""

# --- Carregamento de Configura√ß√µes e Servi√ßos ---
config = get_config()

# Verificar se a chave da API est√° configurada
if not config["google_api_key"]:
    st.error("‚ùå Chave da API do Google n√£o configurada. Por favor, configure a vari√°vel de ambiente GOOGLE_API_KEY no arquivo .env")
    st.stop()

# Verificar se as configura√ß√µes do Supabase est√£o configuradas
if not config["supabase_url"] or not config["supabase_key"]:
    st.warning("‚ö†Ô∏è Configura√ß√µes do Supabase n√£o encontradas. Algumas funcionalidades podem n√£o funcionar. Configure SUPABASE_URL e SUPABASE_KEY no arquivo .env")

memory = SupabaseMemory(url=config["supabase_url"], key=config["supabase_key"])

# --- Interface do Usu√°rio (Sidebar) ---
uploaded_file = build_sidebar(memory, st.session_state.user_id)

# --- L√≥gica Principal de Processamento do CSV ---
if uploaded_file is not None:
    st.sidebar.success("Arquivo CSV carregado com sucesso!")
    if st.session_state.df is None:
            try:
                df, file_hash = load_csv(uploaded_file)
                st.session_state.df = df
                st.session_state.df_info = get_dataset_info(df, uploaded_file.name)

                # Cria uma nova sess√£o no Supabase
                session_id = memory.create_session(
                    dataset_name=uploaded_file.name,
                    dataset_hash=file_hash,
                    user_id=st.session_state.user_id
                )
                
                # Define o ID da sess√£o no estado
                st.session_state.session_id = session_id
                
                # Carrega o hist√≥rico da sess√£o, se existir
                try:
                    session_history = memory.get_session_history(session_id)
                    
                    # Restaura o hist√≥rico de conversas
                    if session_history["conversations"]:
                        st.session_state.conversation_history = "\n".join(
                            f"{'Usu√°rio' if i % 2 == 0 else 'Assistente'}: {msg['question'] if i % 2 == 0 else msg['answer']}"
                            for i, msg in enumerate(session_history["conversations"])
                        )
                    
                    # Restaura as an√°lises
                    if session_history["analyses"]:
                        st.session_state.all_analyses_history = "\n".join(
                            f"An√°lise: {analysis['results'].get('analysis', '')}"
                            for analysis in session_history["analyses"]
                        )
                        
                except Exception as e:
                    st.error(f"Erro ao carregar hist√≥rico da sess√£o: {e}")
                    st.session_state.conversation_history = ""
                    st.session_state.all_analyses_history = f"An√°lise iniciada para o dataset: {uploaded_file.name}\n"
                st.rerun()  # For√ßa recarregamento para mostrar o dataset
            except ValueError as e:
                st.error(f"Erro ao carregar o arquivo: {e}")
                st.session_state.df = None
    else:
        # Dataset j√° carregado, n√£o mostrar mensagem de debug
        pass

# Verifica√ß√£o: se n√£o h√° arquivo carregado mas h√° dados no estado, limpar automaticamente
if uploaded_file is None and st.session_state.get('df') is not None:
    st.sidebar.info("üì§ Nenhum arquivo carregado. Os dados foram limpos automaticamente.")
    # Limpar dados automaticamente
    st.session_state.df = None
    st.session_state.df_info = None
    st.session_state.session_id = None
    st.session_state.messages = []
    st.session_state.conversation_history = ""
    st.session_state.all_analyses_history = ""

# --- √Årea Principal de Exibi√ß√£o ---
st.title("ü§ñ InsightAgent EDA: Seu Assistente de An√°lise de Dados")
st.markdown("Fa√ßa o upload de um arquivo CSV na barra lateral para come√ßar a explorar seus dados.")

if st.session_state.df is not None:
    st.header("Preview do Dataset")
    st.dataframe(st.session_state.df.head())

    st.header("Estat√≠sticas R√°pidas")
    st.json(st.session_state.df_info, expanded=False)

    # --- Interface de Chat ---
    st.header("Converse com seus Dados")

    # Exibe mensagens do hist√≥rico (preservar mensagens existentes)
    for i, message in enumerate(st.session_state.messages):
        display_chat_message(message["role"], message["content"], message.get("chart_fig"), generated_code=message.get("generated_code"))

    # Exibir gr√°fico preservado apenas se ainda n√£o estiver nas mensagens
    if 'last_chart' in st.session_state and st.session_state.last_chart:
        assistant_has_chart = any(
            message.get("role") == "assistant" and message.get("chart_fig") is not None
            for message in st.session_state.messages
        )

        if assistant_has_chart:
            # Evitar duplica√ß√£o removendo o gr√°fico preservado redundante
            del st.session_state.last_chart
            if 'last_chart_code' in st.session_state:
                del st.session_state.last_chart_code
        else:
            st.success("üìä Gr√°fico preservado da an√°lise anterior:")
            try:
                chart_key = f"preserved_chart_{len(st.session_state.messages)}"
                st.plotly_chart(st.session_state.last_chart, use_container_width=True, key=chart_key)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro ao exibir gr√°fico preservado: {e}")
                # Limpar gr√°fico preservado se houver erro
                if 'last_chart' in st.session_state:
                    del st.session_state.last_chart

    # --- Sugest√µes Din√¢micas de Perguntas ---
    st.subheader("Sugest√µes de Perguntas:")

    # Sempre gerar sugest√µes baseadas no hist√≥rico atual
    if st.session_state.conversation_history.strip():
        try:
            dataset_preview = get_dataset_preview(st.session_state.df)

            # Extrair contexto da conversa para melhorar as sugest√µes
            conversation_context = extract_conversation_context(st.session_state.conversation_history)

            # Adicionar contexto ao hist√≥rico para o agente
            enriched_history = st.session_state.conversation_history
            if conversation_context["analysis_types"]:
                enriched_history += f"\n\nTipos de an√°lise realizados: {', '.join(conversation_context['analysis_types'])}"
            if conversation_context["agents_used"]:
                enriched_history += f"\nAgentes utilizados: {', '.join(conversation_context['agents_used'])}"

            # Gerar novas sugest√µes sempre com o hist√≥rico atualizado
            suggestions = generate_dynamic_suggestions(
                api_key=config["google_api_key"],
                dataset_preview=dataset_preview,
                conversation_history=enriched_history
            )

        except Exception as e:
            st.error(f"‚ùå **Erro ao gerar sugest√µes:** {e}")
            suggestions = get_fallback_suggestions()
            st.warning(f"üìù **Usando sugest√µes padr√£o:** {len(suggestions)} sugest√µes")
    else:
        # Se n√£o h√° hist√≥rico, usar sugest√µes padr√£o
        suggestions = get_fallback_suggestions()

    # Garantir que sempre tenhamos sugest√µes
    if not suggestions:
        suggestions = get_fallback_suggestions()
        st.error("‚ö†Ô∏è **Fallback ativado: usando sugest√µes padr√£o**")

    # Exibir as sugest√µes
    st.write(f"üîç **Mostrando {len(suggestions[:3])} sugest√µes:**")
    cols = st.columns(3)
    for i, suggestion in enumerate(suggestions[:3]):
        if cols[i].button(suggestion, use_container_width=True, key=f"suggestion_{i}"):
            st.session_state.last_question = suggestion

    if prompt := st.chat_input("Fa√ßa sua pergunta sobre os dados...") or st.session_state.get('last_question'):
        st.session_state.last_question = None  # Limpa a sugest√£o imediatamente

        # Adiciona a pergunta do usu√°rio ao hist√≥rico e exibe
        st.session_state.messages.append({"role": "user", "content": prompt})
        display_chat_message("user", prompt)

        # Adiciona ao hist√≥rico de texto para os agentes
        st.session_state.conversation_history += f"Usu√°rio: {prompt}\n"
        
        # Inicializa conversation_id como None
        conversation_id = None
        
        # Registrar a conversa no banco de dados
        if st.session_state.session_id:
            try:
                conversation_id = memory.log_conversation(
                    session_id=st.session_state.session_id,
                    question=prompt,
                    answer=""  # A resposta ser√° atualizada quando estiver pronta
                )
            except Exception as e:
                st.error(f"Erro ao registrar conversa: {e}")

        with st.spinner("Analisando e gerando resposta..."):
            try:
                # 1. CoordinatorAgent decide o que fazer
                coordinator_decision = run_coordinator(
                    api_key=config["google_api_key"],
                    df=st.session_state.df,
                    conversation_history=st.session_state.conversation_history,
                    user_question=prompt
                )

                agent_to_call = coordinator_decision.get("agent_to_call")
                question_for_agent = coordinator_decision.get("question_for_agent")
                
                # Inicializa conversation_id como None
                conversation_id = None

                st.info(f"Roteando para: **{agent_to_call}**")
                time.sleep(1)

                bot_response_content = ""
                chart_figure = None
                generated_code = ""

                # 2. Roteia para o agente apropriado
                if agent_to_call == "DataAnalystAgent":
                    bot_response_content = run_data_analyst(
                        api_key=config["google_api_key"],
                        df=st.session_state.df,
                        analysis_context=st.session_state.all_analyses_history,
                        specific_question=question_for_agent
                    )
                    st.session_state.all_analyses_history += f"An√°lise Estat√≠stica:\n{bot_response_content}\n"
                    
                    # Armazenar a an√°lise no banco de dados
                    if st.session_state.session_id:
                        try:
                            memory.store_analysis(
                                session_id=st.session_state.session_id,
                                conversation_id=conversation_id,
                                analysis_type="data_analysis",
                                results={"analysis": bot_response_content}
                            )
                        except Exception as e:
                            st.error(f"Erro ao salvar an√°lise: {e}")

                elif agent_to_call == "VisualizationAgent":
                    try:
                        generated_code = run_visualization(
                            api_key=config["google_api_key"],
                            df=st.session_state.df,
                            analysis_results=st.session_state.all_analyses_history,
                            user_request=question_for_agent
                        )

                        # Tenta executar o c√≥digo para gerar o gr√°fico usando cache
                        try:
                            # Usar cache otimizado para gr√°ficos
                            chart_figure = exec_with_cache(generated_code, st.session_state.df)

                            if chart_figure:
                                bot_response_content = "Aqui est√° a visualiza√ß√£o que voc√™ pediu."
                                st.session_state.all_analyses_history += f"Visualiza√ß√£o Gerada: {question_for_agent}\n"
                            else:
                                bot_response_content = "O c√≥digo foi gerado, mas n√£o criou uma figura v√°lida. Verifique se o c√≥digo define uma vari√°vel 'fig'."
                        except SyntaxError as se:
                            bot_response_content = f"Erro de sintaxe no c√≥digo gerado: {se}\n\nC√≥digo com erro:\n```python\n{generated_code}\n```"
                        except NameError as ne:
                            bot_response_content = f"Erro: vari√°vel n√£o definida no c√≥digo: {ne}\n\nC√≥digo com erro:\n```python\n{generated_code}\n```"
                        except Exception as e:
                            bot_response_content = f"Erro ao executar c√≥digo do gr√°fico: {e}\n\nC√≥digo que falhou:\n```python\n{generated_code}\n```"

                    except Exception as e:
                        bot_response_content = f"Erro no agente de visualiza√ß√£o: {e}\n\nTente reformular sua pergunta ou verifique se sua chave da API do Google est√° configurada corretamente."

                elif agent_to_call == "ConsultantAgent":
                    bot_response_content = run_consultant(
                        api_key=config["google_api_key"],
                        df=st.session_state.df,
                        all_analyses=st.session_state.all_analyses_history,
                        user_question=question_for_agent
                    )
                    
                    # Armazenar a conclus√£o no banco de dados
                    if st.session_state.session_id:
                        try:
                            memory.store_conclusion(
                                session_id=st.session_state.session_id,
                                conversation_id=conversation_id,
                                conclusion_text=bot_response_content,
                                confidence_score=0.9  # Pontua√ß√£o de confian√ßa padr√£o
                            )
                        except Exception as e:
                            st.error(f"Erro ao salvar conclus√£o: {e}")

                elif agent_to_call == "CodeGeneratorAgent":
                    analysis_context = f"Pergunta do usu√°rio: {prompt}\n\nContexto da conversa:\n{st.session_state.all_analyses_history}"
                    generated_code = run_code_generator(
                        api_key=config["google_api_key"],
                        dataset_info=str(st.session_state.df_info),
                        analysis_to_convert=analysis_context
                    )
                    # N√£o incluir o c√≥digo na resposta - ele ser√° exibido automaticamente na interface
                    bot_response_content = "üí° C√≥digo Gerado: Este c√≥digo ser√° executado automaticamente na pr√≥pria interface!"

                else:
                    bot_response_content = "Desculpe, n√£o entendi qual agente usar. Poderia reformular sua pergunta?"

                # 3. Exibe a resposta do bot
                execution_container = None
                results_container = None

                # Executar c√≥digo automaticamente se foi gerado
                if generated_code:
                    # Exibir c√≥digo com containers para execu√ß√£o
                    with st.chat_message("assistant"):
                        st.markdown(bot_response_content)

                        # Sempre exibir o c√≥digo gerado PRIMEIRO
                        execution_container, results_container = display_code_with_streamlit_suggestion(generated_code, auto_execute=True)

                        # Exibir gr√°fico APENAS se foi gerado pelo VisualizationAgent (evita duplica√ß√£o)
                        if chart_figure and agent_to_call == "VisualizationAgent":
                            try:
                                # Usar chave √∫nica para evitar re-renderiza√ß√£o
                                chart_key = f"chart_{len(st.session_state.messages)}_{hash(str(chart_figure))}"
                                st.plotly_chart(chart_figure, use_container_width=True, key=chart_key)
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Erro ao exibir gr√°fico na execu√ß√£o inicial: {str(e)}")

                    # Atualizar a mensagem no hist√≥rico com verifica√ß√£o robusta
                    chart_to_save = chart_figure
                    if chart_figure:
                        try:
                            # Verificar se o gr√°fico √© serializ√°vel
                            chart_figure.to_json()
                        except Exception as e:
                            # Manter o gr√°fico mesmo se n√£o for serializ√°vel
                            pass

                    # Remover deep copy para melhorar performance
                    # chart_to_save = copy.deepcopy(chart_to_save) se necess√°rio

                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": bot_response_content,
                        "chart_fig": chart_to_save,
                        "generated_code": generated_code
                    })

                    if execution_container is None:
                        st.error("‚ùå Erro: Containers n√£o foram criados corretamente!")
                        # N√£o usar return aqui, continuar a execu√ß√£o

                    # Executar o c√≥digo gerado (apenas para CodeGeneratorAgent)
                    if agent_to_call == "CodeGeneratorAgent":
                        try:
                            execution_container.markdown("**Status:** üîÑ Executando c√≥digo Python gerado...")

                            # Criar ambiente seguro para execu√ß√£o
                            local_scope = {
                                "df": st.session_state.df,
                                "pd": pd,
                                "px": px,
                                "go": go,
                                "st": st,
                                "plt": plt,
                                "np": np
                            }

                            # Verificar se o DataFrame est√° dispon√≠vel
                            if st.session_state.df is None:
                                results_container.markdown("**Erro:** Nenhum arquivo CSV foi carregado.")
                                st.error("Erro: Nenhum DataFrame dispon√≠vel para an√°lise.")
                                # N√£o usar return, continuar com o fluxo

                            # Executar o c√≥digo usando cache otimizado
                            exec_with_cache(generated_code, local_scope)

                            # Verificar se foi gerada uma figura
                            if 'fig' in local_scope:
                                execution_container.markdown("**Status:** ‚úÖ C√≥digo executado com sucesso!")
                                results_container.markdown("**Resultados:** Visualiza√ß√£o gerada automaticamente:")

                                # Exibir a figura gerada APENAS UMA VEZ
                                fig = local_scope['fig']
                                # Usar chave √∫nica para evitar re-renderiza√ß√£o
                                fig_key = f"code_chart_{len(st.session_state.messages)}_{id(fig)}"
                                st.plotly_chart(fig, use_container_width=True, key=fig_key)

                                # Atualizar a mensagem para incluir a figura
                                st.session_state.messages[-1]["chart_fig"] = fig
                                chart_figure = fig

                            else:
                                execution_container.markdown("**Status:** ‚úÖ C√≥digo executado com sucesso!")
                                results_container.markdown("**Resultados:** C√≥digo executado sem gerar visualiza√ß√£o espec√≠fica.")

                            # Capturar outras sa√≠das importantes
                            if 'result' in local_scope:
                                results_container.markdown(f"**Valor de retorno:** {local_scope['result']}")
                        except Exception as e:
                            execution_container.markdown(f"**Status:** ‚ùå Erro na execu√ß√£o: {str(e)}")
                            results_container.markdown(f"**Detalhes do erro:** {str(e)}")
                            st.error(f"Erro na execu√ß√£o do c√≥digo: {e}")
                    else:
                        # Para VisualizationAgent, mostrar que o c√≥digo j√° foi executado
                        if execution_container and results_container:
                            execution_container.markdown("**Status:** ‚úÖ C√≥digo executado com sucesso!")
                            results_container.markdown("**Resultados:** Gr√°fico gerado automaticamente acima.")

                else:
                    # Para agentes sem c√≥digo, usar display_chat_message normalmente
                    display_chat_message("assistant", bot_response_content, chart_figure, generated_code=None)

                    # Atualizar a mensagem no hist√≥rico
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": bot_response_content,
                        "chart_fig": chart_figure,
                        "generated_code": None
                    })

                # Atualiza o hist√≥rico de texto AP√ìS processar a resposta
                st.session_state.conversation_history += f"Assistente: {bot_response_content}\n"

                # For√ßar atualiza√ß√£o das sugest√µes na pr√≥xima renderiza√ß√£o
                st.session_state.suggestions = []  # For√ßar regenera√ß√£o

                # 4. Salva no Supabase
                try:
                    chart_json = None
                    if chart_figure:
                        try:
                            # Converter gr√°fico para JSON com timeout protection
                            chart_json = chart_figure.to_json()
                            # Se o JSON for muito grande, truncar para evitar timeout
                            if len(chart_json) > 10000:  # Reduzir limite para ~10KB
                                chart_json = chart_json[:10000] + "\n... (truncado para evitar timeout)"
                        except Exception as json_error:
                            # Se n√£o conseguir converter, salvar apenas metadados b√°sicos
                            st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel converter gr√°fico para JSON: {str(json_error)}")
                            chart_json = f"Gr√°fico gerado ({type(chart_figure).__name__})"

                    # Inicializa a vari√°vel conv_id
                    conv_id = None
                    # Atualizar a conversa existente em vez de criar uma nova
                    if 'conversation_id' in locals() and conversation_id:
                        try:
                            # Atualiza a conversa existente
                            memory.client.table("conversations").update({
                                "answer": bot_response_content,
                                "chart_json": chart_json
                            }).eq("id", conversation_id).execute()
                            conv_id = conversation_id
                        except Exception as e:
                            st.error(f"Erro ao atualizar conversa: {e}")
                    else:
                        # Se n√£o tiver um ID de conversa, cria uma nova
                        try:
                            # Cria uma nova conversa e pega o ID retornado
                            conv_response = memory.log_conversation(
                                session_id=st.session_state.session_id,
                                question=prompt,
                                answer=bot_response_content,
                                chart_json=chart_json
                            )
                            conv_id = conv_response  # Atribui o ID retornado
                        except Exception as e:
                            st.error(f"Erro ao salvar conversa: {e}")
                except Exception as db_error:
                    st.warning(f"‚ö†Ô∏è Erro ao salvar conversa no banco: {str(db_error)}")
                    conv_id = None

                if generated_code:
                    # Tentar salvar o c√≥digo gerado, mas com prote√ß√£o contra timeout
                    try:
                        # Verificar se o c√≥digo √© muito longo (limite de 5000 caracteres)
                        if len(generated_code) > 5000:
                            # Truncar o c√≥digo para evitar timeout
                            truncated_code = generated_code[:5000] + "\n\n# ... (c√≥digo truncado para evitar timeout no banco de dados)"
                            code_to_save = truncated_code
                        else:
                            code_to_save = generated_code

                        memory.store_generated_code(
                            session_id=st.session_state.session_id,
                            conversation_id=conv_id,
                            code_type='visualization' if agent_to_call == "VisualizationAgent" else 'analysis',
                            python_code=code_to_save,
                            description=question_for_agent
                        )
                    except Exception as db_error:
                        # Se houver erro no banco, apenas logar e continuar
                        st.warning(f"‚ö†Ô∏è C√≥digo executado com sucesso, mas houve problema ao salvar: {str(db_error)}")
                        # N√£o interromper o fluxo principal

                # Recarregar a p√°gina para atualizar as sugest√µes com o novo hist√≥rico
                # Mas apenas se estivermos em modo debug OU se n√£o houver gr√°fico para evitar problemas
                should_rerun = False  # Otimiza√ß√£o: reduzir reruns desnecess√°rios

                if chart_figure:
                    # Se h√° gr√°fico, s√≥ fazer rerun em modo debug para evitar problemas de renderiza√ß√£o
                    if DEBUG_MODE:
                        st.success("‚úÖ Resposta processada com sucesso! (Gr√°fico preservado - rerun em modo debug)")
                        should_rerun = True
                    else:
                        st.success("‚úÖ Resposta processada com sucesso!")
                        should_rerun = False
                else:
                    # Se n√£o h√° gr√°fico, rerun √© seguro
                    if DEBUG_MODE:
                        st.success("‚úÖ Resposta processada com sucesso! (Sem gr√°fico - rerun em modo debug)")
                    else:
                        st.success("‚úÖ Resposta processada com sucesso!")
                    should_rerun = False  # Otimiza√ß√£o: evitar rerun desnecess√°rio

                if should_rerun and DEBUG_MODE:
                    st.rerun()

                # FOR√áAR ATUALIZA√á√ÉO DAS SUGEST√ïES AP√ìS CADA RESPOSTA
                st.info("üîÑ Atualizando sugest√µes com o novo contexto...")

                # Preservar gr√°ficos antes do re-run apenas se necess√°rio
                if chart_figure:
                    st.session_state.last_chart = chart_figure
                    st.session_state.last_chart_code = generated_code

                # For√ßar re-run para atualizar sugest√µes com o novo contexto
                # Mas apenas se n√£o estivermos em modo debug para evitar problemas
                if not DEBUG_MODE:
                    time.sleep(0.5)  # Pequena pausa para mostrar a mensagem
                    st.rerun()
                else:
                    st.success("‚úÖ Sugest√µes atualizadas (modo debug - sem re-run)")

                # Limpar gr√°ficos preservados ap√≥s o re-run bem-sucedido
                if 'last_chart' in st.session_state:
                    del st.session_state.last_chart
                if 'last_chart_code' in st.session_state:
                    del st.session_state.last_chart_code

            except Exception as e:
                st.error(f"Ocorreu um erro inesperado: {e}")

# Adiciona um footer
st.markdown("---")
st.markdown("Sistema de An√°lise Explorat√≥ria de Dados com IA - Projeto Acad√™mico")